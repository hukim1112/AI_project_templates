{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c97e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d4e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import session_config\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\" # 사용 gpu 선택\n",
    "session_config.setup_gpus(True, 0.5) # gpu 메모리 사용량 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b417ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c65b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# load your model already built at phase 1.\n",
    "model = tf.keras.models.load_model(\"models/cifar_classifier.h5\")\n",
    "\n",
    "# load your dataset with tf.data\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(train_x, train_y), (test_x, test_y) = cifar10.load_data()\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "train_ds = train_ds.shuffle(buffer_size = 20000, reshuffle_each_iteration=False)\n",
    "val_ds = train_ds.take(10000)\n",
    "train_ds = train_ds.skip(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced763b",
   "metadata": {},
   "source": [
    "# Define customizing function for your model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de5c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(model):\n",
    "    # your loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "    acc = tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n",
    "\n",
    "    class CustomModel(tf.keras.Model):\n",
    "        def train_step(self, data):\n",
    "            x, y = data\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = self(x, training=True)  # Forward pass\n",
    "                # Compute our own loss\n",
    "                loss = loss_fn(y, y_pred)\n",
    "                l2_loss = [tf.nn.l2_loss(t) for t in model.trainable_variables]\n",
    "                l2_loss = self.l2_reg * tf.math.reduce_sum(l2_loss)\n",
    "                total_loss = loss + l2_loss\n",
    "            # Compute gradients\n",
    "            trainable_vars = self.trainable_variables\n",
    "            gradients = tape.gradient(total_loss, trainable_vars)\n",
    "\n",
    "            # Update weights\n",
    "            self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "            # Compute our own metrics\n",
    "            loss_tracker.update_state(loss)\n",
    "            acc.update_state(y, y_pred)\n",
    "            return {\"loss\": loss_tracker.result(), \"acc\": acc.result()}\n",
    "        def test_step(self, data):\n",
    "            # Unpack the data\n",
    "            x, y = data\n",
    "            # Compute predictions\n",
    "            y_pred = self(x, training=False)\n",
    "            # Updates the metrics tracking the loss\n",
    "            loss = loss_fn(y, y_pred)\n",
    "\n",
    "            # Update the metrics.\n",
    "            loss_tracker.update_state(loss)\n",
    "            acc.update_state(y, y_pred)\n",
    "\n",
    "            # Return a dict mapping metric names to current value.\n",
    "            # Note that it will include the loss (tracked in self.metrics).\n",
    "            return {m.name: m.result() for m in self.metrics}\n",
    "        @property\n",
    "        def metrics(self):\n",
    "            # We list our `Metric` objects here so that `reset_states()` can be\n",
    "            # called automatically at the start of each epoch\n",
    "            # or at the start of `evaluate()`.\n",
    "            # If you don't implement this property, you have to call\n",
    "            # `reset_states()` yourself at the time of your choosing.\n",
    "            return [loss_tracker, acc]\n",
    "    return CustomModel(model.input, model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b533400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9304150d",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning\n",
    "\n",
    "주요한 하이퍼파라미터는 다음과 같다. \n",
    "\n",
    "- optimizer = [\"ADAM_W, \"RMSPROP\"]\n",
    "- learning rate = [1E-3, 1E-4, 1E-5]\n",
    "- learning rate scheduler = [constant, piecewise decay, linear decay, cosine decay restart]\n",
    "- batch_size = [32, 64, 128]\n",
    "- weight_decay = [1E-5, 5E-5, 1E-4]\n",
    "\n",
    "리스트에 포함된 파라미터값에 의해 총 2x3x4x3x3 = 216가지 경우의 수에 대해 실험할 수 있다. 각 실험에 대해 Early stopping 지점까지 학습하고 validation 정확도를 측정한다. 우리는 주요한 하이퍼파라미터를 Grid search 방식으로 사전에 결정한다. 이런 방식은 하이퍼파라미터 튜닝에서 더 낮은 차원의 파라미터 공간에 대한 탐색을 수행할 수 있다. 이는 하이퍼파라미터 최적화에 대한 약간의 타협을 통해 효율적인 파라미터 튜닝을 가능하게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hparam_tune import Keras_Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2db4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/home/files/AI_project_templates/logs/tuner_test1\"\n",
    "ckpt_dir = \"/home/files/AI_project_templates/ckpts/tuner_test1\"\n",
    "initial_model_path = \"models/cifar_classifier.h5\"\n",
    "\n",
    "tuner = Keras_Tuner(log_dir, ckpt_dir, initial_model_path, custom_model, train_ds, val_ds, metric=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776b3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = tf.keras.models.load_model(\"ckpts/.../trained_model\")\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "# test_ds = self.test_ds.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "# model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512df4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
